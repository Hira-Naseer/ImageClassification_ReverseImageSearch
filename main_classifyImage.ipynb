{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# IMPORTING ALL LIBRARIES #"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import Sequential\n",
    "from keras.utils import Sequence,to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.layers import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input\n",
    "import pickle\n",
    "from numpy.linalg import norm\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DICTIONARY CONTAING ALL CLASSES #"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class_dict = {\n",
    "    'vehicle': {0:'airplane', 1:'automobile', 2:'ship', 3:'truck'},\n",
    "    'non_vehicle':{0:'bird',1:'cat',2:'deer',3:'dog',4:'frog',5:'horse'}\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# USING DATA GENERATOR FOR DATA AGUMENTATION FOR TRAIN AND TEST CLASS #"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 images belonging to 2 classes.\n",
      "Found 10000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_genertaor = train_datagen.flow_from_directory('cifar10/train',target_size=(150,150),batch_size=64,class_mode='binary')\n",
    "test_genertaor = test_datagen.flow_from_directory('cifar10/test',target_size=(150,150),batch_size=64,class_mode='binary')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BINARY CLASS MODEL #"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(150,150,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 148, 148, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 72, 72, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 34, 34, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 36992)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                2367552   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,463,809\n",
      "Trainable params: 2,463,361\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(filepath='models/model_weights_Binary.h5',\n",
    "                                      monitor='val_accuracy',\n",
    "                                      verbose=1,\n",
    "                                      mode='max',\n",
    "                                      period=2\n",
    "                                      )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "opt = SGD(lr=0.005, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_genertaor,epochs=10,validation_data=test_genertaor, callbacks=[checkpoint_callback])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Accuracy and Loss plot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "his = model.history.history\n",
    "\n",
    "\n",
    "plt.plot(his['loss'], label='Training Loss')\n",
    "plt.plot(his['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MODEL FOR VEHCLE CLASS #"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 4 classes.\n",
      "Found 4000 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "ve_train_genertaor = train_datagen.flow_from_directory('cifar10/train/vehicle',target_size=(150,150),batch_size=64,class_mode='categorical')\n",
    "ve_test_genertaor = test_datagen.flow_from_directory('cifar10/test/vehicle',target_size=(150,150),batch_size=64,class_mode='categorical')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 148, 148, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 74, 74, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 72, 72, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 34, 34, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 17, 17, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 36992)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                2367552   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,463,908\n",
      "Trainable params: 2,463,460\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='models/best_model_weights_cVeh.h5',\n",
    "                                      monitor='val_accuracy',\n",
    "                                      verbose=1,\n",
    "                                      save_best_only=True,\n",
    "                                      mode='max')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "opt = SGD(lr=0.005, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss= 'categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ve_history = model.fit_generator(ve_train_genertaor,epochs=10,validation_data=ve_test_genertaor, callbacks=[checkpoint_callback])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Accuracy and LOss pLot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "his = model.history.history\n",
    "\n",
    "# Plot the metrics\n",
    "plt.plot(his['loss'], label='Training Loss')\n",
    "plt.plot(his['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NON_VEHICLE CLASS MODEL #"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30000 images belonging to 6 classes.\n",
      "Found 6000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "nonVe_train_genertaor = train_datagen.flow_from_directory('cifar10/train/non_vehicle', target_size=(150, 150), batch_size=64,\n",
    "                                                       class_mode='categorical')\n",
    "nonVe_test_genertaor = test_datagen.flow_from_directory('cifar10/test/non_vehicle', target_size=(150, 150), batch_size=64,\n",
    "                                                     class_mode='categorical')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(150, 150, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 150, 150, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 150, 150, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 150, 150, 32)      9248      \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 150, 150, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 75, 75, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 75, 75, 32)        0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 75, 75, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 75, 75, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 75, 75, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 75, 75, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 37, 37, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 37, 37, 64)        0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 37, 37, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 37, 37, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 37, 37, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 37, 37, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 18, 18, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 18, 18, 128)       0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 41472)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               5308544   \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,598,630\n",
      "Trainable params: 5,597,478\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='models/model_weights_cNonVe.h5',\n",
    "                                      monitor='val_accuracy',\n",
    "                                      verbose=1,\n",
    "                                      save_best_only=True,\n",
    "                                      mode='max')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "opt = SGD(lr=0.005, momentum=0.9)\n",
    "# opt = keras.optimizers.Adam(learning_rate=0.005)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: val_accuracy improved from 0.60683 to 0.63633, saving model to models\\model_weights_cNonVe.h5\n",
      "469/469 [==============================] - 4601s 10s/step - loss: 1.0077 - accuracy: 0.6232 - val_loss: 1.4018 - val_accuracy: 0.6363\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.9701 - accuracy: 0.6365\n",
      "Epoch 7: val_accuracy improved from 0.63633 to 0.64217, saving model to models\\model_weights_cNonVe.h5\n",
      "469/469 [==============================] - 4415s 9s/step - loss: 0.9701 - accuracy: 0.6365 - val_loss: 1.0947 - val_accuracy: 0.6422\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.9486 - accuracy: 0.6482\n",
      "Epoch 8: val_accuracy improved from 0.64217 to 0.65200, saving model to models\\model_weights_cNonVe.h5\n",
      "469/469 [==============================] - 4309s 9s/step - loss: 0.9486 - accuracy: 0.6482 - val_loss: 0.9804 - val_accuracy: 0.6520\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.9258 - accuracy: 0.6561\n",
      "Epoch 9: val_accuracy did not improve from 0.65200\n",
      "469/469 [==============================] - 4348s 9s/step - loss: 0.9258 - accuracy: 0.6561 - val_loss: 1.0548 - val_accuracy: 0.6418\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.9025 - accuracy: 0.6659\n",
      "Epoch 10: val_accuracy did not improve from 0.65200\n",
      "469/469 [==============================] - 4290s 9s/step - loss: 0.9025 - accuracy: 0.6659 - val_loss: 1.1551 - val_accuracy: 0.6088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\home\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.8776 - accuracy: 0.6753\n",
      "Epoch 1: val_accuracy improved from 0.65200 to 0.70050, saving model to models\\model_weights_cNonVe.h5\n",
      "469/469 [==============================] - 4347s 9s/step - loss: 0.8776 - accuracy: 0.6753 - val_loss: 0.8415 - val_accuracy: 0.7005\n",
      "Epoch 2/40\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.8673 - accuracy: 0.6795\n",
      "Epoch 2: val_accuracy did not improve from 0.70050\n",
      "469/469 [==============================] - 4333s 9s/step - loss: 0.8673 - accuracy: 0.6795 - val_loss: 0.8657 - val_accuracy: 0.6870\n",
      "Epoch 3/40\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.8461 - accuracy: 0.6895\n",
      "Epoch 3: val_accuracy did not improve from 0.70050\n",
      "469/469 [==============================] - 4341s 9s/step - loss: 0.8461 - accuracy: 0.6895 - val_loss: 0.9160 - val_accuracy: 0.6937\n",
      "Epoch 4/40\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.8302 - accuracy: 0.6942\n",
      "Epoch 4: val_accuracy did not improve from 0.70050\n",
      "469/469 [==============================] - 4342s 9s/step - loss: 0.8302 - accuracy: 0.6942 - val_loss: 0.9803 - val_accuracy: 0.6715\n",
      "Epoch 5/40\n",
      "108/469 [=====>........................] - ETA: 22:30:35 - loss: 0.7977 - accuracy: 0.7056"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(nonVe_train_genertaor, epochs=40, validation_data=nonVe_test_genertaor,\n",
    "                              callbacks=[checkpoint_callback])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Accuracy and Loss Plot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "his = model.history.history\n",
    "\n",
    "# Plot the metrics\n",
    "plt.plot(his['loss'], label='Training Loss')\n",
    "plt.plot(his['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# IMAGE SEARCH MODEL #"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frog\n",
      "airplane\n"
     ]
    }
   ],
   "source": [
    "base_path = 'net_image_dataset'\n",
    "\n",
    "images_path = {}\n",
    "for folders in os.listdir(base_path):\n",
    "    for fol in os.listdir(f'{base_path}/{folders}'):\n",
    "        print(fol)\n",
    "        break\n",
    "        list = []\n",
    "        for file in os.listdir(f'{base_path}/{folders}/{fol}'):\n",
    "\n",
    "            list.append((f'{base_path}/{folders}/{fol}/{file}'))\n",
    "        images_path[f'{folders}/{fol}'] = list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['non_vehicle/frog', 'vehicle/airplane', 'vehicle/car', 'vehicle/truck'])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_path.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet', include_top=False, input_shape=(32,32,3))\n",
    "model.trainable = False\n",
    "\n",
    "model = keras.Sequential([\n",
    "    model,\n",
    "    GlobalMaxPool2D()\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def extract_features(img_path,model):\n",
    "    img = image.load_img(img_path, target_size=(32, 32))\n",
    "    img_array = image.img_to_array(img)\n",
    "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "    preprocessed_img = preprocess_input(expanded_img_array)\n",
    "    pre_model = model.predict(preprocessed_img).flatten()\n",
    "    normalized_result = pre_model/norm(pre_model)\n",
    "    return normalized_result\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "{'non_vehicle/frog': ['net_image_dataset/non_vehicle/frog/istockphoto-1134798796-612x612.jpg',\n  'net_image_dataset/non_vehicle/frog/istockphoto-1347313672-612x612.jpg'],\n 'vehicle/airplane': ['net_image_dataset/vehicle/airplane/14386209.jpeg',\n  'net_image_dataset/vehicle/airplane/40907.jpeg'],\n 'vehicle/car': ['net_image_dataset/vehicle/car/1000558.jpeg',\n  'net_image_dataset/vehicle/car/1003868.jpeg',\n  'net_image_dataset/vehicle/car/1030649.jpeg',\n  'net_image_dataset/vehicle/car/1034662.jpeg',\n  'net_image_dataset/vehicle/car/1090932.jpeg',\n  'net_image_dataset/vehicle/car/1125329.jpeg',\n  'net_image_dataset/vehicle/car/13061205.jpeg',\n  'net_image_dataset/vehicle/car/13356766.jpeg',\n  'net_image_dataset/vehicle/car/14273496.jpeg',\n  'net_image_dataset/vehicle/car/14277864.jpeg',\n  'net_image_dataset/vehicle/car/1456011.jpeg',\n  'net_image_dataset/vehicle/car/15377954.jpeg',\n  'net_image_dataset/vehicle/car/15750673.jpeg',\n  'net_image_dataset/vehicle/car/1600143.jpeg',\n  'net_image_dataset/vehicle/car/16016989.jpeg',\n  'net_image_dataset/vehicle/car/16018122.jpeg',\n  'net_image_dataset/vehicle/car/16033913.jpeg',\n  'net_image_dataset/vehicle/car/16033917.jpeg',\n  'net_image_dataset/vehicle/car/1670584.jpeg',\n  'net_image_dataset/vehicle/car/191842.jpeg',\n  'net_image_dataset/vehicle/car/193997.jpeg',\n  'net_image_dataset/vehicle/car/193998.jpeg',\n  'net_image_dataset/vehicle/car/2086574.jpeg',\n  'net_image_dataset/vehicle/car/2186253.jpeg',\n  'net_image_dataset/vehicle/car/2225728.jpeg',\n  'net_image_dataset/vehicle/car/2343509.jpeg',\n  'net_image_dataset/vehicle/car/2365561.jpeg',\n  'net_image_dataset/vehicle/car/245371.jpeg',\n  'net_image_dataset/vehicle/car/248687.jpeg',\n  'net_image_dataset/vehicle/car/250154.jpeg',\n  'net_image_dataset/vehicle/car/253096.jpeg',\n  'net_image_dataset/vehicle/car/2553411.jpeg',\n  'net_image_dataset/vehicle/car/2575015.jpeg',\n  'net_image_dataset/vehicle/car/257988.jpeg',\n  'net_image_dataset/vehicle/car/2740701.jpeg',\n  'net_image_dataset/vehicle/car/2882234.jpeg',\n  'net_image_dataset/vehicle/car/3007436.jpeg',\n  'net_image_dataset/vehicle/car/3027794.jpeg',\n  'net_image_dataset/vehicle/car/3089843.jpeg',\n  'net_image_dataset/vehicle/car/3422964.jpeg',\n  'net_image_dataset/vehicle/car/3753045.jpeg',\n  'net_image_dataset/vehicle/car/3766620.jpeg',\n  'net_image_dataset/vehicle/car/3772857.png',\n  'net_image_dataset/vehicle/car/4062339.jpeg',\n  'net_image_dataset/vehicle/car/4480462.jpeg',\n  'net_image_dataset/vehicle/car/457418.jpeg',\n  'net_image_dataset/vehicle/car/457609.jpeg',\n  'net_image_dataset/vehicle/car/4887154.jpeg',\n  'net_image_dataset/vehicle/car/5080837.jpeg',\n  'net_image_dataset/vehicle/car/5090487.jpeg',\n  'net_image_dataset/vehicle/car/5094683.jpeg',\n  'net_image_dataset/vehicle/car/5381501.jpeg',\n  'net_image_dataset/vehicle/car/5563065.jpeg',\n  'net_image_dataset/vehicle/car/5717576.jpeg',\n  'net_image_dataset/vehicle/car/5717578.jpeg',\n  'net_image_dataset/vehicle/car/57645.jpeg',\n  'net_image_dataset/vehicle/car/5835580.jpeg',\n  'net_image_dataset/vehicle/car/6109614.jpeg',\n  'net_image_dataset/vehicle/car/6156516.jpeg',\n  'net_image_dataset/vehicle/car/6271391.jpeg',\n  'net_image_dataset/vehicle/car/6552211.jpeg',\n  'net_image_dataset/vehicle/car/6954256.jpeg',\n  'net_image_dataset/vehicle/car/7006139.jpeg',\n  'net_image_dataset/vehicle/car/761984.jpeg',\n  'net_image_dataset/vehicle/car/811034.jpeg',\n  'net_image_dataset/vehicle/car/887843.jpeg',\n  'net_image_dataset/vehicle/car/91152.jpeg',\n  'net_image_dataset/vehicle/car/9117243.jpeg',\n  'net_image_dataset/vehicle/car/945443.jpeg',\n  'net_image_dataset/vehicle/car/9530891.jpeg',\n  'net_image_dataset/vehicle/car/9530901.jpeg'],\n 'vehicle/truck': ['net_image_dataset/vehicle/truck/10213231.jpeg',\n  'net_image_dataset/vehicle/truck/10213233.jpeg',\n  'net_image_dataset/vehicle/truck/1069722.jpeg',\n  'net_image_dataset/vehicle/truck/1078884.jpeg',\n  'net_image_dataset/vehicle/truck/10842993.jpeg',\n  'net_image_dataset/vehicle/truck/10950913.jpeg',\n  'net_image_dataset/vehicle/truck/10995181.jpeg',\n  'net_image_dataset/vehicle/truck/10996089.jpeg',\n  'net_image_dataset/vehicle/truck/10997035.jpeg',\n  'net_image_dataset/vehicle/truck/10999383.jpeg',\n  'net_image_dataset/vehicle/truck/11056016.jpeg',\n  'net_image_dataset/vehicle/truck/11172415.jpeg',\n  'net_image_dataset/vehicle/truck/11218601.jpeg',\n  'net_image_dataset/vehicle/truck/11249020.jpeg',\n  'net_image_dataset/vehicle/truck/11684300.jpeg',\n  'net_image_dataset/vehicle/truck/12112880.jpeg',\n  'net_image_dataset/vehicle/truck/12173399.jpeg',\n  'net_image_dataset/vehicle/truck/12230651.jpeg',\n  'net_image_dataset/vehicle/truck/12387365.jpeg',\n  'net_image_dataset/vehicle/truck/12418932.jpeg',\n  'net_image_dataset/vehicle/truck/12418935.jpeg',\n  'net_image_dataset/vehicle/truck/12421649.jpeg',\n  'net_image_dataset/vehicle/truck/12514450.jpeg',\n  'net_image_dataset/vehicle/truck/12735327.jpeg',\n  'net_image_dataset/vehicle/truck/12735709.jpeg',\n  'net_image_dataset/vehicle/truck/12821559.jpeg',\n  'net_image_dataset/vehicle/truck/129544.jpeg',\n  'net_image_dataset/vehicle/truck/12969796.jpeg',\n  'net_image_dataset/vehicle/truck/13677410.jpeg',\n  'net_image_dataset/vehicle/truck/13687467.jpeg',\n  'net_image_dataset/vehicle/truck/13766333.jpeg',\n  'net_image_dataset/vehicle/truck/13787839.jpeg',\n  'net_image_dataset/vehicle/truck/13917453.jpeg',\n  'net_image_dataset/vehicle/truck/13926794.jpeg',\n  'net_image_dataset/vehicle/truck/13931434.jpeg',\n  'net_image_dataset/vehicle/truck/13965982.jpeg',\n  'net_image_dataset/vehicle/truck/13965989.jpeg',\n  'net_image_dataset/vehicle/truck/13990550.jpeg',\n  'net_image_dataset/vehicle/truck/14018572.jpeg',\n  'net_image_dataset/vehicle/truck/14023348.jpeg',\n  'net_image_dataset/vehicle/truck/14023379.jpeg',\n  'net_image_dataset/vehicle/truck/14156803.jpeg',\n  'net_image_dataset/vehicle/truck/14159216.jpeg',\n  'net_image_dataset/vehicle/truck/14159300.jpeg',\n  'net_image_dataset/vehicle/truck/14180356.jpeg',\n  'net_image_dataset/vehicle/truck/14180400.jpeg',\n  'net_image_dataset/vehicle/truck/14199930.jpeg',\n  'net_image_dataset/vehicle/truck/14505907.png',\n  'net_image_dataset/vehicle/truck/14716120.jpeg',\n  'net_image_dataset/vehicle/truck/14930736.jpeg',\n  'net_image_dataset/vehicle/truck/15526517.jpeg',\n  'net_image_dataset/vehicle/truck/16142510.jpeg',\n  'net_image_dataset/vehicle/truck/16143828.jpeg',\n  'net_image_dataset/vehicle/truck/16150134.jpeg',\n  'net_image_dataset/vehicle/truck/1654504.jpeg',\n  'net_image_dataset/vehicle/truck/2059643.jpeg',\n  'net_image_dataset/vehicle/truck/210107.jpeg',\n  'net_image_dataset/vehicle/truck/2101140.jpeg',\n  'net_image_dataset/vehicle/truck/2217075.jpeg',\n  'net_image_dataset/vehicle/truck/2221122.jpeg',\n  'net_image_dataset/vehicle/truck/226460.jpeg',\n  'net_image_dataset/vehicle/truck/2315228.jpeg',\n  'net_image_dataset/vehicle/truck/2519383.jpeg',\n  'net_image_dataset/vehicle/truck/2542324.jpeg',\n  'net_image_dataset/vehicle/truck/2888320.jpeg',\n  'net_image_dataset/vehicle/truck/2959588.jpeg',\n  'net_image_dataset/vehicle/truck/3089685.jpeg',\n  'net_image_dataset/vehicle/truck/4524231.jpeg',\n  'net_image_dataset/vehicle/truck/4529769.jpeg',\n  'net_image_dataset/vehicle/truck/5769320.jpeg',\n  'net_image_dataset/vehicle/truck/5774998.jpeg',\n  'net_image_dataset/vehicle/truck/5774999.jpeg',\n  'net_image_dataset/vehicle/truck/5779663.jpeg',\n  'net_image_dataset/vehicle/truck/5779664.jpeg',\n  'net_image_dataset/vehicle/truck/5779740.jpeg',\n  'net_image_dataset/vehicle/truck/5779779.jpeg',\n  'net_image_dataset/vehicle/truck/5779781.jpeg',\n  'net_image_dataset/vehicle/truck/5800758.jpeg',\n  'net_image_dataset/vehicle/truck/5804282.jpeg',\n  'net_image_dataset/vehicle/truck/583142.jpeg',\n  'net_image_dataset/vehicle/truck/5875432.jpeg',\n  'net_image_dataset/vehicle/truck/5920626.jpeg',\n  'net_image_dataset/vehicle/truck/5920629.jpeg',\n  'net_image_dataset/vehicle/truck/5920631.jpeg',\n  'net_image_dataset/vehicle/truck/5920761.jpeg',\n  'net_image_dataset/vehicle/truck/5920774.jpeg',\n  'net_image_dataset/vehicle/truck/5968200.jpeg',\n  'net_image_dataset/vehicle/truck/6026765.jpeg',\n  'net_image_dataset/vehicle/truck/6161660.jpeg',\n  'net_image_dataset/vehicle/truck/6169649.jpeg',\n  'net_image_dataset/vehicle/truck/6169650.jpeg',\n  'net_image_dataset/vehicle/truck/6169651.jpeg',\n  'net_image_dataset/vehicle/truck/6199674.jpeg',\n  'net_image_dataset/vehicle/truck/6214911.jpeg',\n  'net_image_dataset/vehicle/truck/6275446.jpeg',\n  'net_image_dataset/vehicle/truck/68353.jpeg',\n  'net_image_dataset/vehicle/truck/7287113.jpeg',\n  'net_image_dataset/vehicle/truck/7287114.jpeg',\n  'net_image_dataset/vehicle/truck/7295164.jpeg',\n  'net_image_dataset/vehicle/truck/730129.jpeg',\n  'net_image_dataset/vehicle/truck/7339934.jpeg',\n  'net_image_dataset/vehicle/truck/7473141.jpeg',\n  'net_image_dataset/vehicle/truck/7494748.jpeg',\n  'net_image_dataset/vehicle/truck/7539625.jpeg',\n  'net_image_dataset/vehicle/truck/7539626.jpeg',\n  'net_image_dataset/vehicle/truck/7541346.jpeg',\n  'net_image_dataset/vehicle/truck/7541348.jpeg',\n  'net_image_dataset/vehicle/truck/7541353.jpeg',\n  'net_image_dataset/vehicle/truck/7541354.jpeg',\n  'net_image_dataset/vehicle/truck/7730803.jpeg',\n  'net_image_dataset/vehicle/truck/7763697.jpeg',\n  'net_image_dataset/vehicle/truck/7967360.jpeg',\n  'net_image_dataset/vehicle/truck/7967405.jpeg',\n  'net_image_dataset/vehicle/truck/8066253.jpeg',\n  'net_image_dataset/vehicle/truck/8438566.jpeg',\n  'net_image_dataset/vehicle/truck/8438568.jpeg',\n  'net_image_dataset/vehicle/truck/8622817.jpeg',\n  'net_image_dataset/vehicle/truck/8622819.jpeg',\n  'net_image_dataset/vehicle/truck/8919749.jpeg',\n  'net_image_dataset/vehicle/truck/8920045.jpeg',\n  'net_image_dataset/vehicle/truck/8943259.jpeg',\n  'net_image_dataset/vehicle/truck/8948315.jpeg',\n  'net_image_dataset/vehicle/truck/9247585.jpeg',\n  'net_image_dataset/vehicle/truck/9300187.jpeg',\n  'net_image_dataset/vehicle/truck/9301046.jpeg',\n  'net_image_dataset/vehicle/truck/968398.jpeg',\n  'net_image_dataset/vehicle/truck/977213.jpeg',\n  'net_image_dataset/vehicle/truck/9796843.jpeg',\n  'net_image_dataset/vehicle/truck/9798871.jpeg',\n  'net_image_dataset/vehicle/truck/9940001.jpeg',\n  'net_image_dataset/vehicle/truck/9957862.jpeg']}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001F95D9D4E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001F95D9D4E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 0s 104ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:06<00:19,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:07<00:06,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [01:04<00:27, 27.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 1s 591ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 419ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 1s 503ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [02:36<00:00, 39.18s/it]\n"
     ]
    }
   ],
   "source": [
    "features = {}\n",
    "for file in tqdm(images_path):\n",
    "    list = []\n",
    "    for data in images_path[file]:\n",
    "        list.append(extract_features(data, model))\n",
    "    features[file] = list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "for data in features:\n",
    "    name = data.replace('/','_')\n",
    "    pickle.dump(features[data], open(f'features_{name}.pkl', 'wb'))\n",
    "    pickle.dump(images_path[data], open(f'filenames_{name}.pkl', 'wb'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PIPELINE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def pipeline(test_img):\n",
    "    test_img = Image.open(test_img)\n",
    "    b_model = keras.models.load_model('models/best_model_weights_Binary.h5')\n",
    "    cnn_model_veh = keras.models.load_model('models/model_weights_cVeh.h5')\n",
    "    cnn_model_nonVeh = keras.models.load_model('models/model_weights_cNonVe.h5')\n",
    "\n",
    "    img = test_img.resize((150,150))\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    pred_img = b_model.predict(img)\n",
    "\n",
    "    # mul_img = test_img.resize((32,32))\n",
    "    # mul_img = np.expand_dims(mul_img, axis=0)\n",
    "\n",
    "    predictions = np.array([])\n",
    "    if pred_img < 0.5  and pred_img >= 0:\n",
    "        predictions = cnn_model_nonVeh.predict(test_img)\n",
    "    elif(pred_img > 0.5):\n",
    "        predictions = cnn_model_veh.predict(test_img)\n",
    "\n",
    "    predicted_class = np.argmax(predictions,axis=-1)\n",
    "    prediction = \"\"\n",
    "    if pred_img < 0.5:\n",
    "        prediction = 'non_vehicle/'\n",
    "        prediction = prediction + class_dict['non_vehicle'][predicted_class[0]]\n",
    "    elif pred_img > 0.5:\n",
    "        prediction = 'vehicle/'\n",
    "        prediction = prediction + class_dict['vehicle'][predicted_class[0]]\n",
    "\n",
    "    t_img = test_img.resize((32,32))\n",
    "    img_array = image.img_to_array(t_img)\n",
    "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "    preprocessed_img = preprocess_input(expanded_img_array)\n",
    "    pre_model = model.predict(preprocessed_img).flatten()\n",
    "    normalized_result = pre_model/norm(pre_model)\n",
    "\n",
    "    features_list = {}\n",
    "    filenames = {}\n",
    "\n",
    "    for files in images_path:\n",
    "        name = files.replace('/','_')\n",
    "        features_list[files] = np.array(pd.read_pickle(f'features_{name}.pkl'))\n",
    "        filenames[files] = pd.read_pickle(open(f'filenames_{name}.pkl','rb'))\n",
    "\n",
    "\n",
    "    neighbors = NearestNeighbors(n_neighbors = 7,algorithm='brute',metric='euclidean')\n",
    "    neighbors.fit(features_list[prediction])\n",
    "\n",
    "    distances, indices = neighbors.kneighbors(normalized_result.reshape(1,-1))\n",
    "    file_list = filenames[prediction]\n",
    "\n",
    "    list = []\n",
    "    for i in indices[0]:\n",
    "        list.append(file_list[i])\n",
    "\n",
    "    return prediction.split('/')[0],prediction.split('/')[1],list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002BC8ECD7288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002BC8ECD7288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'PIL.JpegImagePlugin.JpegImageFile'>, <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_11780\\2268460504.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mpipeline\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'uploads/image.jpg'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_11780\\2998941909.py\u001B[0m in \u001B[0;36mpipeline\u001B[1;34m(test_img)\u001B[0m\n\u001B[0;32m     16\u001B[0m         \u001B[0mpredictions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcnn_model_nonVeh\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_img\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m     \u001B[1;32melif\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpred_img\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0.5\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m         \u001B[0mpredictions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcnn_model_veh\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_img\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m     \u001B[0mpredicted_class\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0margmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpredictions\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     68\u001B[0m             \u001B[1;31m# To get the full stack trace, call:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m             \u001B[1;31m# `tf.debugging.disable_traceback_filtering()`\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 70\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     71\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     72\u001B[0m             \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\data_adapter.py\u001B[0m in \u001B[0;36mselect_data_adapter\u001B[1;34m(x, y)\u001B[0m\n\u001B[0;32m   1081\u001B[0m         raise ValueError(\n\u001B[0;32m   1082\u001B[0m             \"Failed to find data adapter that can handle input: {}, {}\".format(\n\u001B[1;32m-> 1083\u001B[1;33m                 \u001B[0m_type_name\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_type_name\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1084\u001B[0m             )\n\u001B[0;32m   1085\u001B[0m         )\n",
      "\u001B[1;31mValueError\u001B[0m: Failed to find data adapter that can handle input: <class 'PIL.JpegImagePlugin.JpegImageFile'>, <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "pipeline('uploads/image.jpg')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}